{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation\n",
    "\n",
    "**ICS3206 - Course Project (Jupyter Notebook #1)**\n",
    "\n",
    "---\n",
    "\n",
    "**Name:** Andrea Filiberto Lucas  \n",
    "**ID No:** 0279704L\n",
    "\n",
    "---\n",
    "\n",
    "## Importing Necessary Libraries\n",
    "\n",
    "\n",
    "Essential libraries are imported in this section. ANSI escape codes are defined to enhance the readability of console messages with colored text. A mapping between PyPI package names and their corresponding import names is established to facilitate automated package management. Functions are provided to check for the presence of required packages and install any that are missing using `pip`. Once all dependencies are ensured, necessary modules such as OpenCV, NumPy, Pillow, Matplotlib, IPyWidgets, and IPython are imported to support image processing, concurrent execution, data manipulation, and visualization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package 'opencv-python' is already installed.\n",
      "Package 'numpy' is already installed.\n",
      "Package 'Pillow' is already installed.\n",
      "Package 'matplotlib' is already installed.\n",
      "Package 'ipywidgets' is already installed.\n",
      "Package 'IPython' is already installed.\n",
      "Package 'tqdm' is already installed.\n",
      "\u001b[92mAll required packages are installed and imported successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "#         IMPORTS          #\n",
    "############################\n",
    "\n",
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# ANSI escape codes for colored text (optional, for better readability)\n",
    "GREEN = \"\\033[92m\"\n",
    "RED = \"\\033[91m\"\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "# Mapping of PyPI package names to their import names\n",
    "# Format: 'package-name': 'import-name'\n",
    "# For submodules, use the top-level package name as the import name\n",
    "packages = {\n",
    "    'opencv-python': 'cv2',\n",
    "    'numpy': 'numpy',\n",
    "    'Pillow': 'PIL',\n",
    "    'matplotlib': 'matplotlib',\n",
    "    'ipywidgets': 'ipywidgets',  # Added ipywidgets\n",
    "    'IPython': 'IPython',        # Added IPython\n",
    "    'tqdm': 'tqdm',              # Added tqdm\n",
    "}\n",
    "\n",
    "def install_package(package_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Install a package using pip.\n",
    "    \n",
    "    Args:\n",
    "        package_name (str): The name of the package to install.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"Installing package: {package_name}\")\n",
    "        # Use subprocess to run the pip install command\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n",
    "        print(f\"{GREEN}Successfully installed {package_name}.{RESET}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        # Print the error message in red\n",
    "        print(f\"{RED}Failed to install package {package_name}. Error: {e}{RESET}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def check_and_install_packages(packages_dict: dict) -> None:\n",
    "    \"\"\"\n",
    "    Check if the packages are installed, and install them if they are missing.\n",
    "    \n",
    "    Args:\n",
    "        packages_dict (dict): A dictionary mapping package names to their import names.\n",
    "    \"\"\"\n",
    "    for package, import_name in packages_dict.items():\n",
    "        try:\n",
    "            # Attempt to import the package\n",
    "            importlib.import_module(import_name.split('.')[0])\n",
    "            print(f\"Package '{package}' is already installed.\")\n",
    "        except ImportError:\n",
    "            print(f\"Package '{package}' is not installed. Installing now...\")\n",
    "            install_package(package)\n",
    "\n",
    "# Check and install the required packages\n",
    "check_and_install_packages(packages)\n",
    "\n",
    "# Now, import the packages after ensuring they are installed\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Additional Imports\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Print the success message in green\n",
    "print(f\"{GREEN}All required packages are installed and imported successfully.{RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directory Selection\n",
    "\n",
    "This section enables the selection of input and output directories using an interactive dropdown widget. Users can choose a specific constellation directory or select \"All\" to include all available directories. Upon selection, the script verifies the existence and non-emptiness of the chosen input directories and creates the corresponding output directories if they do not already exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88881eb5eae040499db1c89ec6acc5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Directory:', layout=Layout(width='300px'), options=('All', 'CoronaBorealis', 'Lac…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cc5e7d1226c4a46a0afc0723f3683a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#############################\n",
    "#     DIRECTORY SELECTION   #\n",
    "#############################\n",
    "\n",
    "# List of available directory options with \"All\" as the first option\n",
    "available_dirs = [\n",
    "    \"All\",  \n",
    "    \"CoronaBorealis\", \"Lacerta\", \"LeoMinor\", \"Lepus\", \"Norma\", \n",
    "    \"Pisces\", \"Sextans\", \"Virgo\"\n",
    "]\n",
    "\n",
    "# Create a Dropdown widget for directory selection\n",
    "dir_dropdown = widgets.Dropdown(\n",
    "    options=available_dirs,\n",
    "    description='Select Directory:',\n",
    "    disabled=False,\n",
    "    layout=widgets.Layout(width='300px'),  \n",
    "    style={'description_width': '102px'}   \n",
    ")\n",
    "\n",
    "# Create an Output widget to display messages\n",
    "output = widgets.Output()\n",
    "\n",
    "# Initialize global variables\n",
    "input_dir = []  \n",
    "output_dir = []  \n",
    "\n",
    "def on_dir_change(change):\n",
    "    \"\"\"\n",
    "    Callback function to handle directory selection changes.\n",
    "    Sets the input and output directories, performs checks,\n",
    "    and displays relevant messages.\n",
    "    \"\"\"\n",
    "    global input_dir, output_dir\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        selected_dir = change['new']\n",
    "        \n",
    "        with output:\n",
    "            clear_output()\n",
    "            \n",
    "            if selected_dir == \"All\":\n",
    "                # Set input_dir and output_dir to include all directories\n",
    "                input_dir = [Path(f'../8CD/{dir_name}') for dir_name in available_dirs if dir_name != \"All\"]\n",
    "                output_dir = [Path(f'../8CD/{dir_name}_augmented') for dir_name in available_dirs if dir_name != \"All\"]\n",
    "                \n",
    "                # Check if all input directories exist and are not empty\n",
    "                missing_dirs = [dir_path for dir_path in input_dir if not dir_path.exists()]\n",
    "                empty_dirs = [dir_path for dir_path in input_dir if not any(dir_path.iterdir())]\n",
    "                \n",
    "                if missing_dirs:\n",
    "                    for dir_path in missing_dirs:\n",
    "                        print(f\"{RED}The input directory '{dir_path}' does not exist.{RESET}\")\n",
    "                    return\n",
    "                \n",
    "                if empty_dirs:\n",
    "                    for dir_path in empty_dirs:\n",
    "                        print(f\"{RED}The input directory '{dir_path}' is empty.{RESET}\")\n",
    "                    return\n",
    "                \n",
    "                # Create all output directories if they do not exist\n",
    "                for out_dir in output_dir:\n",
    "                    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # Display the valid directories\n",
    "                print(f\"{GREEN}Valid Input Directories: {[str(dir_path) for dir_path in input_dir]}{RESET}\")\n",
    "                print(f\"{GREEN}Valid Output Directories: {[str(dir_path) for dir_path in output_dir]}{RESET}\")\n",
    "            \n",
    "            else:\n",
    "                # Set input_dir and output_dir for a single directory\n",
    "                input_dir = [Path(f'../8CD/{selected_dir}')]\n",
    "                output_dir = [Path(f'../8CD/{selected_dir}_augmented')]\n",
    "                \n",
    "                input_path = input_dir[0]\n",
    "                output_path = output_dir[0]\n",
    "                \n",
    "                # Check if the input directory exists\n",
    "                if not input_path.exists():\n",
    "                    print(f\"{RED}The input directory '{input_path}' does not exist.{RESET}\")\n",
    "                    return\n",
    "                \n",
    "                # Check if the input directory contains any files\n",
    "                if not any(input_path.iterdir()):\n",
    "                    print(f\"{RED}The input directory '{input_path}' is empty.{RESET}\")\n",
    "                    return\n",
    "                \n",
    "                # Create the output directory if it does not exist\n",
    "                output_path.mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "                # Display the valid directories\n",
    "                print(f\"{GREEN}Valid Input Directory: {input_path}{RESET}\")\n",
    "                print(f\"{GREEN}Valid Output Directory: {output_path}{RESET}\")\n",
    "\n",
    "# Attach the callback to the Dropdown\n",
    "dir_dropdown.observe(on_dir_change)\n",
    "\n",
    "# Display the Dropdown and Output widgets\n",
    "display(dir_dropdown, output)\n",
    "\n",
    "# Set a default selection to the first directory (not \"All\")\n",
    "default_dir = available_dirs[1]  # Index 1 since \"All\" is at index 0\n",
    "dir_dropdown.value = default_dir  # This will trigger the callback and display directories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brightness and Contrast Adjustment\n",
    "\n",
    "This function adjusts the brightness and contrast of an input image. It accepts an image in the form of a NumPy array or a PIL Image and applies specified brightness and contrast levels within predefined bounds. The adjustments are performed using the `ImageEnhance` module from Pillow, ensuring that the output image maintains visual consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_brightness_contrast(img, brightness=0, contrast=0):\n",
    "    # Ensure the input is a valid image (either NumPy array or PIL Image)\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img = Image.fromarray(img)  # Convert NumPy array to PIL Image if needed\n",
    "    elif not isinstance(img, Image.Image):\n",
    "        raise TypeError(\"Input image must be a NumPy array or a PIL Image - apply_brightness_contrast\")\n",
    "\n",
    "    # Ensure brightness and contrast are within reasonable bounds\n",
    "    brightness = max(-100, min(brightness, 100))\n",
    "    contrast = max(-100, min(contrast, 100))\n",
    "    # Apply brightness and contrast adjustments\n",
    "    enhancer_b = ImageEnhance.Brightness(img)\n",
    "    img = enhancer_b.enhance(1 + brightness / 100.0)\n",
    "    enhancer_c = ImageEnhance.Contrast(img)\n",
    "    img = enhancer_c.enhance(1 + contrast / 100.0)\n",
    "\n",
    "    return np.array(img)  # Return the result as a NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Addition\n",
    "\n",
    "This function introduces Gaussian noise to an input image to simulate real-world imperfections and enhance data variability. It accepts an image as a NumPy array and applies noise with specified mean and standard deviation values. The function ensures that the input is a valid NumPy array, generates the Gaussian noise, and adds it to the image while maintaining pixel values within the valid 8-bit range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img, mean=0, stddev=25):\n",
    "    # Ensure the input image is a NumPy array\n",
    "    if not isinstance(img, np.ndarray):\n",
    "        raise TypeError(\"Input image must be a NumPy array - add_noise\")\n",
    "\n",
    "    # Generate Gaussian noise\n",
    "    noise = np.random.normal(mean, stddev, img.shape).astype(np.float32)\n",
    "    # Add the noise to the image\n",
    "    noisy_img = cv2.add(img.astype(np.float32), noise)\n",
    "    # Clip values to ensure they stay within valid 8-bit range [0, 255]\n",
    "    noisy_img = np.clip(noisy_img, 0, 255).astype(np.uint8)\n",
    "\n",
    "    return noisy_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur Application\n",
    "\n",
    "This function applies Gaussian blur to an input image to smooth out details and reduce noise. It accepts an image as a NumPy array and a kernel size (`ksize`) which must be a positive odd integer. The function verifies that the kernel size meets the required conditions and then utilizes OpenCV's `GaussianBlur` method to perform the blurring operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_blur(img, ksize=5):\n",
    "    # Ensure ksize is a positive odd integer\n",
    "    if not isinstance(ksize, int) or ksize <= 0 or ksize % 2 == 0:\n",
    "        raise ValueError(\"Kernel size (ksize) must be a positive odd integer - apply_blur\")\n",
    "\n",
    "    # Apply Gaussian blur with the given kernel size\n",
    "    blurred_img = cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
    "\n",
    "    return blurred_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skew Transformation\n",
    "\n",
    "This function applies a skew transformation to an input image, introducing perspective distortion to simulate real-world angular variations. It accepts an image as a NumPy array and parameters for skew factor and skew angle. The function validates the input to ensure it is a valid RGB or RGBA image, defines source and destination points for the affine transformation, and computes the transformation matrix using OpenCV's `getAffineTransform` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_skew(img, skew_factor=0.1, skew_angle=0.33):\n",
    "    # Ensure the input is a valid image (NumPy array)\n",
    "    if not isinstance(img, np.ndarray):\n",
    "        raise TypeError(\"Input image must be a NumPy array.\")\n",
    "    \n",
    "    if img.ndim != 3 or img.shape[2] not in [3, 4]:  # Checking for RGB or RGBA images\n",
    "        raise ValueError(\"Input image must be a 3-channel (RGB) or 4-channel (RGBA) image.\")\n",
    "\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # Define source and destination points for the affine transformation\n",
    "    pts1 = np.float32([[0, 0], [cols, 0], [0, rows]])\n",
    "    pts2 = np.float32([\n",
    "        [cols * skew_factor, rows * skew_angle],  # Skewing the top-left corner\n",
    "        [cols * (1 - skew_factor), rows * (skew_angle - 0.08)],  # Skewing the top-right corner\n",
    "        [cols * skew_factor, rows * (1 - skew_angle)]  # Skewing the bottom-left corner\n",
    "    ])\n",
    "\n",
    "    # Get the affine transformation matrix\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "    # Apply the affine transformation (skewing)\n",
    "    skewed_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "    return skewed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Transformation\n",
    "\n",
    "This function scales an image by a specified factor to simulate size variations. It accepts an image as a NumPy array and a positive scale factor, calculates the new dimensions, and resizes the image using OpenCV's `resize` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scaling(img, scale=1.2):\n",
    "    # Ensure the input is a valid image (NumPy array)\n",
    "    if not isinstance(img, np.ndarray):\n",
    "        raise TypeError(\"Input image must be a NumPy array.\")\n",
    "    \n",
    "    if img.ndim != 3:\n",
    "        raise ValueError(\"Input image must be a 3-channel (RGB) or 4-channel (RGBA) image.\")\n",
    "    \n",
    "    if scale <= 0:\n",
    "        raise ValueError(\"Scale factor must be a positive value.\")\n",
    "\n",
    "    # Get the original dimensions of the image\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    # Calculate new dimensions based on the scale factor\n",
    "    new_width = int(width * scale)\n",
    "    new_height = int(height * scale)\n",
    "\n",
    "    # Ensure that the new dimensions are positive\n",
    "    if new_width <= 0 or new_height <= 0:\n",
    "        raise ValueError(\"Scaling factor results in invalid image dimensions.\")\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (new_width, new_height))\n",
    "\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotation Transformation\n",
    "\n",
    "This function rotates an image by a random angle within a specified range. It calculates the rotation matrix using OpenCV's `getRotationMatrix2D` and applies the transformation to the image using `warpAffine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rotation(img, max_angle=15):\n",
    "    \"\"\"Rotate the image by a random angle within the given range.\"\"\"\n",
    "    rows, cols, ch = img.shape\n",
    "    angle = random.uniform(-max_angle, max_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    rotated_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "    return rotated_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flip Transformation\n",
    "\n",
    "This function flips an image either horizontally or vertically. It accepts the image as a NumPy array and a flip type (`horizontal` or `vertical`). The OpenCV `flip` function performs the operation, and the flipped image is returned, enabling various image augmentation scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_flip(img, flip_type=\"horizontal\"):\n",
    "    \"\"\"Flip the image either horizontally or vertically.\"\"\"\n",
    "    if flip_type == \"horizontal\":\n",
    "        return cv2.flip(img, 1)  # Horizontal flip\n",
    "    elif flip_type == \"vertical\":\n",
    "        return cv2.flip(img, 0)  # Vertical flip\n",
    "    else:\n",
    "        raise ValueError(\"flip_type must be either 'horizontal' or 'vertical'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Jitter\n",
    "\n",
    "This function randomly adjusts the brightness, contrast, saturation, and hue of an image to simulate different lighting conditions. It operates in the HSV color space, making pixel-wise adjustments before converting the image back to BGR format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_color_jitter(img, brightness=0, contrast=0, saturation=0, hue=0):\n",
    "    \"\"\"Randomly adjust brightness, contrast, saturation, and hue of the image.\"\"\"\n",
    "    hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Apply brightness\n",
    "    hsv_img[:, :, 2] = np.clip(hsv_img[:, :, 2] + brightness, 0, 255)\n",
    "    \n",
    "    # Apply contrast\n",
    "    hsv_img[:, :, 1] = np.clip(hsv_img[:, :, 1] + contrast, 0, 255)\n",
    "    \n",
    "    # Apply saturation\n",
    "    hsv_img[:, :, 1] = np.clip(hsv_img[:, :, 1] + saturation, 0, 255)\n",
    "    \n",
    "    # Apply hue\n",
    "    hsv_img[:, :, 0] = np.clip(hsv_img[:, :, 0] + hue, 0, 179)\n",
    "    \n",
    "    jittered_img = cv2.cvtColor(hsv_img, cv2.COLOR_HSV2BGR)\n",
    "    return jittered_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transformation\n",
    "\n",
    "This function applies a perspective transformation to create a warped view of an image. The transformation strength determines the degree of distortion, with corner points shifted proportionally. OpenCV's `getPerspectiveTransform` computes the transformation matrix, and `warpPerspective` applies it to the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perspective_transform(img, strength=1.0):\n",
    "    \"\"\"Apply a perspective transformation to the image with a given strength.\"\"\"\n",
    "    rows, cols, _ = img.shape\n",
    "\n",
    "    # The strength will control how much the corners of the image are shifted\n",
    "    shift_x = cols * (0.1 * strength)  # Horizontal shift based on strength\n",
    "    shift_y = rows * (0.1 * strength)  # Vertical shift based on strength\n",
    "    \n",
    "    # Define the original and transformed points\n",
    "    pts1 = np.float32([[0, 0], [cols, 0], [0, rows], [cols, rows]])\n",
    "    pts2 = np.float32([\n",
    "        [shift_x, shift_y], \n",
    "        [cols - shift_x, shift_y], \n",
    "        [shift_x, rows - shift_y], \n",
    "        [cols - shift_x, rows - shift_y]\n",
    "    ])\n",
    "    \n",
    "    # Compute the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    \n",
    "    # Apply the perspective warp\n",
    "    warped_img = cv2.warpPerspective(img, M, (cols, rows))\n",
    "    return warped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation and Processing\n",
    "\n",
    "This section performs data augmentation on images from the input directories and saves the augmented results in the corresponding output directories. The process includes:\n",
    "\n",
    "1. **Directory Setup:**\n",
    "   - The base directory is defined, and input/output directories are validated and created if necessary.\n",
    "   - All image files from the input directory are collected for processing.\n",
    "\n",
    "2. **Image Augmentation:**\n",
    "   - Various transformations are applied to each image, including adjustments for brightness, contrast, noise, blur, skew, scaling, rotation, flipping, color jitter, and perspective transformations.\n",
    "   - Each transformation produces a uniquely augmented image with a descriptive filename.\n",
    "\n",
    "3. **Progress Monitoring:**\n",
    "   - The `tqdm` library provides a progress bar to track the processing of images within each directory.\n",
    "\n",
    "4. **Output:**\n",
    "   - The augmented images are saved in their respective output directories with appropriate names reflecting the applied transformation.\n",
    "\n",
    "This process enhances the dataset by increasing variability, which is beneficial for tasks requiring robust training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Templates in /Users/afl/Documents/University/Year 3/Lectures/SEM1/Advanced ML/Constellation-Finder/8CD/../8CD/CoronaBorealis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Templates: 100%|██████████| 10/10 [00:03<00:00,  2.65file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Templates in /Users/afl/Documents/University/Year 3/Lectures/SEM1/Advanced ML/Constellation-Finder/8CD/../8CD/Lacerta:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Templates: 100%|██████████| 10/10 [00:06<00:00,  1.56file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Templates in /Users/afl/Documents/University/Year 3/Lectures/SEM1/Advanced ML/Constellation-Finder/8CD/../8CD/LeoMinor:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Templates: 100%|██████████| 8/8 [00:03<00:00,  2.12file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Templates in /Users/afl/Documents/University/Year 3/Lectures/SEM1/Advanced ML/Constellation-Finder/8CD/../8CD/Lepus:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Templates: 100%|██████████| 10/10 [00:07<00:00,  1.41file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Templates in /Users/afl/Documents/University/Year 3/Lectures/SEM1/Advanced ML/Constellation-Finder/8CD/../8CD/Norma:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Templates: 100%|██████████| 10/10 [00:05<00:00,  1.84file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Templates in /Users/afl/Documents/University/Year 3/Lectures/SEM1/Advanced ML/Constellation-Finder/8CD/../8CD/Pisces:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Templates: 100%|██████████| 10/10 [00:06<00:00,  1.53file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Templates in /Users/afl/Documents/University/Year 3/Lectures/SEM1/Advanced ML/Constellation-Finder/8CD/../8CD/Sextans:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Templates: 100%|██████████| 10/10 [00:03<00:00,  3.20file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Templates in /Users/afl/Documents/University/Year 3/Lectures/SEM1/Advanced ML/Constellation-Finder/8CD/../8CD/Virgo:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Templates: 100%|██████████| 10/10 [00:05<00:00,  1.90file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mData augmentation completed successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##########################\n",
    "#    Data Augmentation   #\n",
    "##########################\n",
    "# Define the base directory for '8CD' as being one level up from the current working directory\n",
    "base_dir = Path(os.getcwd()).parent / \"8CD\"\n",
    "\n",
    "# Loop through all images in the input directory\n",
    "for idx, (in_dir, out_dir) in enumerate(zip(input_dir, output_dir)):\n",
    "    # Construct the full paths for input and output directories\n",
    "    in_dir = base_dir / in_dir\n",
    "    out_dir = base_dir / out_dir\n",
    "\n",
    "    # Ensure the input directory exists\n",
    "    if not in_dir.exists():\n",
    "        print(f\"Error: Input directory '{in_dir}' does not exist. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Ensure the output directory exists or create it\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get the list of image files\n",
    "    image_files = [f for f in os.listdir(in_dir) if f.endswith((\".jpg\", \".png\"))]\n",
    "    total_files = len(image_files)\n",
    "\n",
    "    if total_files == 0:\n",
    "        print(f\"No images found in directory '{in_dir}'. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing Templates in {in_dir}:\")\n",
    "\n",
    "    # Use tqdm to create a progress bar\n",
    "    for filename in tqdm(image_files, desc=\"Processing Templates\", unit=\"file\"):\n",
    "        img_path = in_dir / filename\n",
    "\n",
    "        # Read the image and check if it's loaded correctly\n",
    "        img = cv2.imread(str(img_path))  # Ensure path is string\n",
    "        if img is None:\n",
    "            print(f\"Warning: Failed to load image {filename}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Apply various augmentations with different values for each transformation\n",
    "        augmented_images = [\n",
    "            (\"brightness_contrast_+30_+30\", apply_brightness_contrast(img, brightness=30, contrast=30)),\n",
    "            (\"brightness_contrast_-30_-30\", apply_brightness_contrast(img, brightness=-30, contrast=-30)),\n",
    "            (\"brightness_contrast_+50_+50\", apply_brightness_contrast(img, brightness=50, contrast=50)),\n",
    "            (\"brightness_contrast_-50_-50\", apply_brightness_contrast(img, brightness=-50, contrast=-50)),\n",
    "            (\"noise_25\", add_noise(img)),\n",
    "            (\"noise_50\", add_noise(img, mean=0, stddev=50)),\n",
    "            (\"blur_ksize_3\", apply_blur(img, ksize=3)),\n",
    "            (\"blur_ksize_5\", apply_blur(img, ksize=5)),\n",
    "            (\"blur_ksize_9\", apply_blur(img, ksize=9)),\n",
    "            (\"skew\", apply_skew(img)),\n",
    "            (\"skew_stronger\", apply_skew(img, skew_factor=1.5)),\n",
    "            (\"scaling_1.1\", apply_scaling(img, scale=1.1)),\n",
    "            (\"scaling_0.9\", apply_scaling(img, scale=0.9)),\n",
    "            (\"scaling_1.2\", apply_scaling(img, scale=1.2)),\n",
    "            (\"scaling_0.8\", apply_scaling(img, scale=0.8)),\n",
    "            (\"rotation_15\", apply_rotation(img, max_angle=15)),\n",
    "            (\"rotation_30\", apply_rotation(img, max_angle=30)),\n",
    "            (\"rotation_45\", apply_rotation(img, max_angle=45)),\n",
    "            (\"flip_horizontal\", apply_flip(img, flip_type=\"horizontal\")),\n",
    "            (\"flip_vertical\", apply_flip(img, flip_type=\"vertical\")),\n",
    "            (\"color_jitter_10_10_10_5\", apply_color_jitter(img, brightness=10, contrast=10, saturation=10, hue=5)),\n",
    "            (\"color_jitter_30_30_30_15\", apply_color_jitter(img, brightness=30, contrast=30, saturation=30, hue=15)),\n",
    "            (\"perspective_transform\", apply_perspective_transform(img)),\n",
    "            (\"perspective_transform_strong\", apply_perspective_transform(img, strength=1.5)),\n",
    "        ]\n",
    "        \n",
    "        # Save augmented images with descriptive names\n",
    "        for aug_name, aug_img in augmented_images:\n",
    "            if aug_img is not None:  # Ensure the transformed image is valid\n",
    "                aug_img_path = out_dir / f\"{Path(filename).stem}_{aug_name}.png\"\n",
    "                cv2.imwrite(str(aug_img_path), aug_img)\n",
    "\n",
    "# Print the success message in green\n",
    "print(f\"{GREEN}Data augmentation completed successfully.{RESET}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
